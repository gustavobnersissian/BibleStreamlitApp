import streamlit as st
import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from wordcloud import WordCloud
import nltk
from nltk.corpus import stopwords
import string

# Ensure NLTK stopwords are downloaded
nltk.download('stopwords')
stop_words = set(stopwords.words('portuguese'))  # Adjust for language

# Load the Bible JSON file
@st.cache_data
def load_biblia():
    with open("nvi.json", "r", encoding="utf-8-sig") as file:
        return json.load(file)

biblia_data = load_biblia()

# Mapping abbreviations to full book names
book_names = {
    "gn": "G√™nesis", "ex": "√äxodo", "lv": "Lev√≠tico", "nm": "N√∫meros", "dt": "Deuteron√¥mio",
    "js": "Josu√©", "jd": "Ju√≠zes", "rt": "Rute", "1sm": "1 Samuel", "2sm": "2 Samuel",
    "1rs": "1 Reis", "2rs": "2 Reis", "1cr": "1 Cr√¥nicas", "2cr": "2 Cr√¥nicas", "ed": "Esdras",
    "ne": "Neemias", "et": "Ester", "j√≥": "J√≥", "sl": "Salmos", "pv": "Prov√©rbios",
    "ec": "Eclesiastes", "ct": "Cantares", "is": "Isa√≠as", "jr": "Jeremias", "lm": "Lamenta√ß√µes",
    "ez": "Ezequiel", "dn": "Daniel", "os": "Oseias", "jl": "Joel", "am": "Am√≥s",
    "ob": "Obadias", "jn": "Jonas", "mq": "Miqueias", "na": "Naum", "hc": "Habacuque",
    "sf": "Sofonias", "ag": "Ageu", "zc": "Zacarias", "ml": "Malaquias",
    "mt": "Mateus", "mc": "Marcos", "lc": "Lucas", "jo": "Jo√£o",
    "atos": "Atos", "rm": "Romanos", "1co": "1 Cor√≠ntios", "2co": "2 Cor√≠ntios",
    "gl": "G√°latas", "ef": "Ef√©sios", "fp": "Filipenses", "cl": "Colossenses",
    "1ts": "1 Tessalonicenses", "2ts": "2 Tessalonicenses", "1tm": "1 Tim√≥teo", "2tm": "2 Tim√≥teo",
    "tt": "Tito", "fm": "Filemom", "hb": "Hebreus", "tg": "Tiago", "1pe": "1 Pedro",
    "2pe": "2 Pedro", "1jo": "1 Jo√£o", "2jo": "2 Jo√£o", "3jo": "3 Jo√£o", "jd": "Judas", "ap": "Apocalipse"
}

# Sidebar: Select Book
book_abbr = st.sidebar.selectbox("Selecione um livro", options=[b["abbrev"] for b in biblia_data], format_func=lambda x: book_names.get(x, x))

# Get book data
selected_book = next(b for b in biblia_data if b["abbrev"] == book_abbr)
book_title = book_names.get(book_abbr, book_abbr)

# Sidebar: Select Chapter
chapter_options = ["Todos"] + [str(i + 1) for i in range(len(selected_book["chapters"]))]
selected_chapter = st.sidebar.selectbox("Selecione um cap√≠tulo", chapter_options)

# Sidebar: Select Verse
if selected_chapter == "Todos":
    verse_options = ["Todos"]
else:
    verse_options = ["Todos"] + [str(i + 1) for i in range(len(selected_book["chapters"][int(selected_chapter) - 1]))]

selected_verse = st.sidebar.selectbox("Selecione um vers√≠culo", verse_options)

# Extracting text
def get_text(book, chapter, verse):
    if chapter == "Todos":
        return [verse for chap in book["chapters"] for verse in chap]
    elif verse == "Todos":
        return book["chapters"][int(chapter) - 1]
    else:
        return [book["chapters"][int(chapter) - 1][int(verse) - 1]]

text_data = get_text(selected_book, selected_chapter, selected_verse)

# Display Book and Chapter
st.title(f"üìñ {book_title}")
if selected_chapter == "Todos":
    st.subheader("Todos os cap√≠tulos")
elif selected_verse == "Todos":
    st.subheader(f"Cap√≠tulo {selected_chapter}")
else:
    st.subheader(f"Vers√≠culo {selected_verse} - Cap√≠tulo {selected_chapter}")

# Display verses
for i, verse in enumerate(text_data, 1):
    st.markdown(f"**{i}** {verse}")

# üîπ WORD CLOUD
st.subheader("‚òÅ Nuvem de palavras")

word_freq = Counter(" ".join(text_data).lower().translate(str.maketrans("", "", string.punctuation)).split())
word_freq = {word: count for word, count in word_freq.items() if word not in stop_words}

wordcloud = WordCloud(width=800, height=400, background_color="white", colormap="Blues", max_words=100).generate_from_frequencies(word_freq)

fig, ax = plt.subplots(figsize=(10, 5))
ax.imshow(wordcloud, interpolation="bilinear")
ax.axis("off")
st.pyplot(fig)

# üîπ WORD FREQUENCY BAR CHART
st.subheader("üìä Palavras mais frequentes")

df_word_freq = pd.DataFrame(word_freq.items(), columns=["Palavra", "Frequ√™ncia"]).nlargest(10, "Frequ√™ncia")

fig, ax = plt.subplots(figsize=(8, 5))
sns.barplot(y=df_word_freq["Palavra"], x=df_word_freq["Frequ√™ncia"], palette="Blues_r", ax=ax)
ax.set_xlabel("Frequ√™ncia")
ax.set_ylabel("Palavra")
st.pyplot(fig)

# üîπ VERSE LENGTH OVER TIME (LINE CHART)
st.subheader("üìà Comprimento dos vers√≠culos por cap√≠tulo")

verse_lengths = [len(" ".join(chap).split()) for chap in selected_book["chapters"]]
df_verse_lengths = pd.DataFrame({"Cap√≠tulo": range(1, len(verse_lengths) + 1), "Palavras": verse_lengths})

fig, ax = plt.subplots(figsize=(8, 5))
sns.lineplot(x="Cap√≠tulo", y="Palavras", data=df_verse_lengths, marker="o", ax=ax)
ax.set_ylabel("Total de palavras")
ax.set_xlabel("Cap√≠tulo")
st.pyplot(fig)

# üîπ DISTRIBUTION OF VERSE WORD COUNTS (HISTOGRAM)
st.subheader("‚è≥ Distribui√ß√£o do tamanho dos vers√≠culos")

all_verses = [len(verse.split()) for chap in selected_book["chapters"] for verse in chap]
fig, ax = plt.subplots(figsize=(8, 5))
sns.histplot(all_verses, bins=15, kde=True, color="blue", ax=ax)
ax.set_xlabel("N√∫mero de palavras por vers√≠culo")
ax.set_ylabel("Frequ√™ncia")
st.pyplot(fig)
